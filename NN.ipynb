{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from math import floor, ceil\n",
    "from pylab import rcParams\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(style='ticks', palette='Spectral', font_scale=1.5)\n",
    "\n",
    "material_palette = [\"#4CAF50\", \"#2196F3\", \"#9E9E9E\", \"#FF9800\", \"#607D8B\", \"#9C27B0\"]\n",
    "sns.set_palette(material_palette)\n",
    "rcParams['figure.figsize'] = 16, 8\n",
    "\n",
    "plt.xkcd();\n",
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "tf.set_random_seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = sqlite3.connect('DB')\n",
    "train_x = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM train_x\n",
    "\"\"\", engine)\n",
    "train_y = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM train_y\n",
    "\"\"\", engine)\n",
    "\n",
    "train_size = 0.8\n",
    "train_cnt = floor(train_x.shape[0] * train_size)\n",
    "x_train = train_x.iloc[0: train_cnt].values\n",
    "y_train = train_y.iloc[0: train_cnt].values\n",
    "x_test = train_x.iloc[train_cnt:].values\n",
    "y_test = train_y.iloc[train_cnt:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases, keep_prob):\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_1 = tf.nn.dropout(layer_1, keep_prob)\n",
    "    out_layer = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_hidden_1 = 38\n",
    "n_input = train_x.shape[1]#15 for 15 columns(the features)\n",
    "n_classes = train_y.shape[1]#1 for 1 column(the labels)\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_1, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "keep_prob = tf.placeholder('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_epochs = 50\n",
    "display_step = 10\n",
    "batch_size = 32\n",
    "\n",
    "x = tf.placeholder('float', [None, n_input])\n",
    "y = tf.placeholder('float', [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-db249069908a>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = multilayer_perceptron(x, weights, biases, keep_prob)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(len(train_x.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "#     for epoch in range(training_epochs):\n",
    "#         avg_cost = 0.0\n",
    "#         total_batch = int(len(x_train) / batch_size)\n",
    "#         x_batches = np.array_split(x_train, total_batch)\n",
    "#         y_batches = np.array_split(y_train, total_batch)\n",
    "#         for i in range(total_batch):\n",
    "#             batch_x, batch_y = x_batches[i], y_batches[i]\n",
    "#             _, c = sess.run([optimizer, cost],\n",
    "#                            feed_dict = {\n",
    "#                                x: batch_x,\n",
    "#                                y: batch_y,\n",
    "#                                keep_prob: 0.8\n",
    "#                            })\n",
    "#             avg_cost += c / total_batch\n",
    "#         if epoch % display_step == 0:\n",
    "#             print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "#                 \"{:.9f}\".format(avg_cost))\n",
    "#     print('Done')\n",
    "#     correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "#     print(\"Accuracy:\", accuracy.eval({x: x_test, y: y_test, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim = 16, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer = 'normal'))\n",
    "    \n",
    "    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input_dim is number of columns\n",
    "model.add(Dense(16, input_dim = 16, kernel_initializer = 'normal', activation = 'relu'))\n",
    "That means it the layer has 16 nodes and expects 16 features(input variables)\n",
    "\n",
    "model.add(Dense(8, activation='relu'))\n",
    "This layer has 8 neurons\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "This layer 1 neuron which you apply the sigmoid function to get an output\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "To compile the model\n",
    "\n",
    "model.fit(X, Y, epochs=150, batch_size=10)\n",
    "#Fit model\n",
    "\n",
    "scores = model.evaluate(test_X, test_Y)\n",
    "#Test model\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -650103326.50 (345345011.83) MSE\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=20, batch_size=250, verbose=0)\n",
    "kfold = KFold(n_splits = 10, random_state = seed)\n",
    "results = cross_val_score(estimator, x_train, y_train, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
