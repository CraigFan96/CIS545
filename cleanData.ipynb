{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from math import floor, ceil\n",
    "from pylab import rcParams\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "engine = sqlite3.connect('DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write code to convert CSV to Pandas. Pretty sure I lost it somewhere\n",
    "test = pd.read_csv('./test.csv')\n",
    "baseTrain = pd.read_csv('./train.csv')\n",
    "featuresDf = pd.read_csv('./features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combining training data with the features\n",
    "storesWithTrain = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM trainDf\n",
    "JOIN storesDf \n",
    "ON storesDf.Store = trainDf.Store\n",
    "\"\"\", engine)\n",
    "_, i = np.unique(storesWithTrain.columns, return_index = True)\n",
    "storesWithTrain = storesWithTrain.iloc[:, i]\n",
    "storesWithTrain.to_sql('storesWithTrain', engine, if_exists='replace', index = False)\n",
    "\n",
    "everything = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM storesWithTrain\n",
    "JOIN featuresDf\n",
    "ON storesWithTrain.Store = featuresDf.Store AND storesWithTrain.Date = featuresDf.Date\n",
    "\"\"\", engine)\n",
    "\n",
    "#Get all unique elements\n",
    "_, i = np.unique(everything.columns, return_index = True)\n",
    "everything = everything.iloc[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Grabbing just the basic features that match with the testing data\n",
    "baseTrain_y = baseTrain['Weekly_Sales']\n",
    "baseTrain_x = baseTrain.drop('Weekly_Sales', axis = 1)\n",
    "baseTrain_x['Date'] = baseTrain_x['Date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "baseTrain_x['Date'] = baseTrain_x['Date'].apply(lambda x: int(time.mktime(x.timetuple())) / 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cleaning the data that has everything\n",
    "\n",
    "#Parsing the data/convert data time to milliseconds\n",
    "train_x = everything.drop_duplicates()\n",
    "train_x = train_x.dropna().reset_index(drop = True)#Get rid of this line if you don't want to drop NaN\n",
    "\n",
    "#Convert date string to date time object to get milliseconds\n",
    "train_x['Date'] = train_x['Date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "train_x['Date'] = train_x['Date'].apply(lambda x: int(time.mktime(x.timetuple())) / 100000)\n",
    "\n",
    "test['Date'] = test['Date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "test['Date'] = test['Date'].apply(lambda x: int(time.mktime(x.timetuple())) / 100000)\n",
    "\n",
    "train_y = train_x['Weekly_Sales']\n",
    "train_y = train_y.to_frame()\n",
    "train_y = train_y.dropna().reset_index(drop = True)\n",
    "train_x.drop('Weekly_Sales', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Optional cell if you want to remove NaNs. This will mainly remove the MarkDown rows\n",
    "#One hot code for everything data\n",
    "storeType = train_x['Type']\n",
    "encoding = pd.get_dummies(storeType)\n",
    "\n",
    "train_x['A'] = encoding['A']\n",
    "train_x['B'] = encoding['B']\n",
    "train_x['C'] = encoding['C']\n",
    "train_x.drop('Type', axis = 1, inplace = True)\n",
    "train_x = train_x.dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x.to_sql('train_x', engine, if_exists = 'replace', index = False)\n",
    "train_y.to_sql('train_y', engine, if_exists = 'replace', index = False)\n",
    "test.to_sql('test', engine, if_exists='replace', index = False)\n",
    "baseTrain_x.to_sql('baseTrain_x', engine, if_exists='replace', index = False)\n",
    "baseTrain_y.to_sql('baseTrain_y', engine, if_exists='replace', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
